{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Linear regression is the most basic type of regression commonly used for\n",
    "predictive analysis. The idea is preety simple, we have a dataset and we have\n",
    "a feature's associated with it. The Features should be choose very cautiously\n",
    "as they determine, how much our model will be able to make future predictions.\n",
    "We try to set these Feature weights, over many iterations, so that they best\n",
    "fits our dataset. In this particular code, i had used a CSGO dataset (ADR vs\n",
    "Rating). We try to best fit a line through dataset and estimate the parameters.\n",
    "'''\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def collect_dataset():\n",
    "    '''\n",
    "    Collect dataset of CSGO\n",
    "    The dataset contains ADR vs Rating of a Player\n",
    "    :return : dataset obtained from the link, as matrix\n",
    "    '''\n",
    "    response = requests.get('https://raw.githubusercontent.com/yashLadha/' +\n",
    "                            'The_Math_of_Intelligence/master/Week1/ADRvs' +\n",
    "                            'Rating.csv')\n",
    "    lines = response.text.splitlines()\n",
    "    data = []\n",
    "    for item in lines:\n",
    "        item = item.split(',')\n",
    "        data.append(item)\n",
    "    data.pop(0)  # This is for removing the labels from the list\n",
    "    dataset = np.matrix(data)\n",
    "    return dataset\n",
    "\n",
    "def run_steep_gradient_descent(data_x, data_y,\n",
    "                               len_data, alpha, theta):\n",
    "    \"\"\" Run steep gradient descent and updates the Feature vector accordingly_\n",
    "    :param data_x   : contains the dataset\n",
    "    :param data_y   : contains the output associated with each data-entry\n",
    "    :param len_data : length of the data_\n",
    "    :param alpha    : Learning rate of the model\n",
    "    :param theta    : Feature vector (weight's for our model)\n",
    "    ;param return   : Updated Feature's, using\n",
    "                       curr_features - alpha_ * gradient(w.r.t. feature)\n",
    "    \"\"\"\n",
    "    n = len_data\n",
    "    prod = np.dot(theta, data_x.transpose())\n",
    "    prod -= data_y.transpose()\n",
    "    sum_grad = np.dot(prod, data_x)\n",
    "    theta = theta - (alpha / n) * sum_grad\n",
    "    return theta\n",
    "\n",
    "\n",
    "def sum_of_square_error(data_x, data_y, len_data, theta):\n",
    "    \"\"\" Return sum of square error for error calculation\n",
    "    :param data_x    : contains our dataset\n",
    "    :param data_y    : contains the output (result vector)\n",
    "    :param len_data  : len of the dataset\n",
    "    :param theta     : contains the feature vector\n",
    "    :return          : sum of square error computed from given feature's\n",
    "    \"\"\"\n",
    "    error = 0.0\n",
    "    prod = np.dot(theta, data_x.transpose())\n",
    "    prod -= data_y.transpose()\n",
    "    sum_elem = np.sum(np.square(prod))\n",
    "    error = sum_elem / (2 * len_data)\n",
    "    return error\n",
    "\n",
    "\n",
    "def run_linear_regression(data_x, data_y):\n",
    "    '''\n",
    "    Implement Linear regression over the dataset\n",
    "    :param data_x  : contains our dataset\n",
    "    :param data_y  : contains the output (result vector)\n",
    "    :return        : feature for line of best fit (Feature vector)\n",
    "    '''\n",
    "    iterations = 100000\n",
    "    alpha = 0.0001550\n",
    "\n",
    "    no_features = data_x.shape[1]\n",
    "    len_data = data_x.shape[0] - 1\n",
    "\n",
    "    theta = np.zeros((1, no_features))\n",
    "\n",
    "    for i in range(0, iterations):\n",
    "        theta = run_steep_gradient_descent(data_x, data_y,\n",
    "                                           len_data, alpha, theta)\n",
    "        error = sum_of_square_error(data_x, data_y, len_data, theta)\n",
    "        print('At Iteration %d - Error is %.5f ' % (i + 1, error))\n",
    "        pass\n",
    "    return theta\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = collect_dataset()\n",
    "\n",
    "    len_data = data.shape[0]\n",
    "    data_x = np.c_[np.ones(len_data), data[:, :-1]].astype(float)\n",
    "    data_y = data[:, -1].astype(float)\n",
    "\n",
    "    theta = run_linear_regression(data_x, data_y)\n",
    "    len_result = theta.shape[1]\n",
    "    print('Resultant Feature vector : ')\n",
    "    for i in range(0, len_result):\n",
    "        print('%.5f' % (theta[0, i]))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
